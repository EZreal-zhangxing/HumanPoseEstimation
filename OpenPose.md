# OpenPose

## Introduce

是一个自下而上的框架。提出通过部分亲和场(Part Affinity Fields，PAFs)给出的关联分数表示(用来计算身体部分的相似度)。部分亲和场是一个2D向量字段，它编码了四肢在图像中的位置和方向信息。

## Method

![image-20220405111402355](D:\HumanPose\image-20220405111402355.png)

Input：原始图片

1. 通过前馈网络，生成身体部分位置的2D置信图$S$ 见$Fig:2b$，以及由部分亲合场(PAFs)组成的2D向量场$L$。这个字段对身体部位之间的角度进行编码$Fig:2c$。

$S = (S_1,S_2,\ldots,S_J)$ 有$J$个置信图，一个身体部分对应一个元素。$S_j \in \mathbb R^{w\times h} \ 其中\ j \in \{1,\ldots,J\}$

$L = (L_1,L_2,\ldots,L_c)$有$C$个向量字段，每个肢体对应一个元素。$L_c \in \mathbb R^{w \times h \times 2}\ 其中 \ c \in \{1,\ldots,C\}$

我们将一对$S_{i,j}$身体部分划分成一个肢体$L_x$，但是有些地方并不是肢体，比如说脸。

在$L_c$中的每个图像位置都被编码成2D向量

![image-20220405125404024](D:\HumanPose\image-20220405125404024.png)

Top：属于同一人的身体部件被连接到一起，包括脚关键点(大脚趾，小脚趾和脚后跟)

left：对右手胳膊和右手手腕肢体的PAFs编码，颜色标识编码方向

Right：在每个肢体的PAFs中，每个像素编码了肢体的位置和方向(2D 向量)

2. 最后通过贪婪推理$Fig:2d$解析置信度图和PAFs。输出所有人的2D关键点图$Fig:2e$

### Network Architecture

![image-20220405130241223](D:\HumanPose\image-20220405130241223.png)

第一部分（蓝色部分）预测PAFs $L^t$,后一部分（橘色部分）预测置信度图$S^t$，每个阶段的预测和对应的图像特征进行拼接(Concat)给到每个阶段的子阶段。原始方法中卷积核为7被使用3层卷积核大小为3的卷积所替代，并且这三层卷积会在末尾拼接(Concat)

### Simultaneous Detection and Association

图像首先被VGG-19的前十层进行处理，生成Feature Map $F$输入到第一阶段，在这极端，网络生成PAFs的集合。
$$
L^1 = \phi^1(F)
$$
$L^1$为第一阶段的输出，$\phi^1$是第一阶段的网络函数。在每个子阶段中，图像原始FeatureMap($F$)与前一子阶段的预测拼接起来产生更精细的预测
$$
L^t = \phi^t(F,L^t-1),\forall 2 \le t \le T_p
$$
在$T_p$轮迭代后，进行置信图的检测。
$$
S^{T_p} = \rho^t(F,L^{T_p}),\forall t = T_p\\
S^t = \rho^t(F,L^{T_p},S^{t-1}),\forall T_p\lt t \le T_P+T_c
$$
$\rho$表示置信图计算的网路函数

每个阶段都有对应的损失：

第一阶段PAFs的损失：
$$
f_L^{t_i} = \sum_{c=1}^C \sum_pW(p) \cdot||L_c^{t_i}(p) - L_c^*(p)||_2^2
$$
$L_c^*$是第$c$个肢体PAFs的GT

第二阶段损失：
$$
f_S^{t_k} = \sum_{j=1}^J \sum_pW(p) \cdot||S_j^{t_k}(p) - S_j^*(p)||_2^2
$$
$S_j^*$是GT的置信度Map

$W$是一个二进制，当像素$p$的标注缺失时$W(p) = 0$，这个值是用来避免在训练时候惩罚TP。每个阶段中间还会定期补充梯度以解决梯度消失的问题

总损失为：
$$
f = \sum_{t=1}^{T_p}f_L^t + \sum_{t = T_p+1}^{T_p+T_c}f_S^t
$$

### Confidence Maps

每个置信度Map都是特定身体部分能否在任意像素中被定位的可信程度的表示。理想情况下，一个人出现在画面中并且相关的部分可见，那么置信度Map就会有一个单一的峰值。对于多个人来说，就应该有一个峰值对应每个人（$k$）的每个肢体部位 ($j$)

首先生成每个人($k$)的置信度Map
$$
S_{j,k}^*(P) = \exp(- {||p-x_{j,k}||_2^2 \over {\delta^2}})
$$
$x_{j,k} \in  \mathbb R^2$是第$k$个人的第$j$个部位的GT位置。$\delta$控制峰值的宽窄 $\delta$越大波峰越平坦，越小越陡峭

**GT的置信度图是通过聚合所有人的相同部位的置信度图，进行$Max$运算得到的**
$$
S_j^*(p) = \max_k S_{j,k}^*(p)
$$
此处不使用平均值而使用最大值，是为了保证峰值周围可区分，在测试的时候，预测置信度Map后通过非极大值抑制获取最终的候选部位

![image-20220405153854992](D:\HumanPose\image-20220405153854992.png)

### Part Affinity Fields For part Association

![image-20220405154032059](D:\HumanPose\image-20220405154032059.png)

本节讨论如何解决身体部分匹配关联的问题：给定了多个人的身体部分，如何使他们匹配并组装成，数量未知并且个体完整的人

思路：对每对身体部分计算他的置信度(每一对身体部分属于同一个人的置信度)。每个红蓝点组成一对，

一个可能的方法就是检测每对之间的中间点，并检查候选检测之间的关联性$Fig:b$，但是人聚集在一起的时候可能会导致错误的关联(见绿线)，这种错误关联的原因因为表示的两条限制

1. 只对位置进行了编码，没有编码方向
2. 将肢体区域缩小成了一个点

PAFs解决了这两个问题，保留了位置和方向信息见$Fig:c$，对于特定肢体区域的每个像素点，都会有一个2D向量会对该肢体指向其他肢体的方向进行编码，每种肢体类型都有对应的PAFs连接两个关联的身体部分

考虑如下的肢体：

![image-20220405160528536](D:\HumanPose\image-20220405160528536.png)

$x_{j_1,k}、x_{j_2,k}$是肢体$c$上身体部分$j_1$、$j_2$的GT位置，如果点$p$在肢体上，那么$L_{c,k}^*(p)$的值是$j_1$到$j_2$的单位向量。对于其他点该向量都是0值

更具上述可得第$k$人第$c$个肢体的PAFs的GT定义式如下：
$$
L_{c,k}^*(p)
\begin{cases}
v & if \ p \  on \  limb \  c,k\\
0 & else\\
\end{cases}
$$
其中$v$是单位向量 $v = {(x_{j_2,k} - x_{j_1,k}) \over ||x_{j_2,k} - x_{j_1,k}||_2^2}$，也就是说在GT上，肢体上的区域各个地方都相等都等于肢体两个端点之间的单位向量。肢体区域的点集定义为在线段距离阈值内的点
$$
0 \le v \cdot (p-x_{j_1,k}) \le l_{c,k} \ \cap \ |v_\bot\cdot (p-x_{j_1,k})| \le \delta_l
$$
$\delta_l$是肢体宽度=像素上的距离，肢体长度$l_{c,k} = ||x_{j_2,k} - x_{j_1,k}||_2^2$ 。$v_\bot$垂直于$v$

**向量$p$分别在$v,v_\bot$的投影分别要小于$l_{c,k},\delta_l$**

最终的PAFs定义为所有人的第$c$肢体的PAFs**平均和**
$$
L_c^*(p) = {1 \over n_c(p)} \sum_kL_{c,k}^*(p)
$$
$n_c(p)$为是所有人在点$p$非零向量的个数

#### 计算相似度

测试的时候我们通过计算 候选身体部分位置的连线在对应的PAF上的线积分来测量两个候选区域的连通程度

对于两个候选制
$$
E = \int_{u=0}^{u=1}L_c(p(u))\cdot {d_{j_2} - d_{j_1} \over ||d_{j_2} - d_{j_1}||_2}du
$$
其中$p(u) = (1-u)d_{j_1}+u d_{j_2}$，这是一个加权得到的坐标，$L_c(p(u))$函数表示去肢体$c$的PAF找到对应坐标的值。实际上我们通过间隔均匀的对$u$采样求$E$

### Multi-Person Parsing using PAFs

对检测置信度图进行非极大值抑制，以获得一组零散的候选肢体。然后用等式$(12)$对这些肢体进行评分。这是一个已知的$k$维匹配问题，难度系数$NP-Hard$。所以我们提出了一种贪婪算法来进行高质量的匹配

定义多人身体部分检测的候选集合$D_J$

$D_J = \{d_j^m : for \ j \in \{1,\ldots,J\},m \in \{ 1,\ldots,N_j\}\}$

$N_j$是身体部分$j$的候选数量，$d_J^m \in \mathbb R^2$ 是身体部分$j$的第$m$个候选的坐标

要做的事情是，寻找任意身体部分对能够组成肢体

定义$z_{j_1,j_2}^{mn} \in \{0,1\}$来表示候选$d_{j_1}^m,d_{j_2}^n$是否连通，目标是找到一种所有可能连通的 $Z = \{z_{j_1,j_2}^{mn}\}$的最优分配

考虑两个单一的身体部分$j_1,j_2$作为第$c$个肢体。找到最佳关联将转化成**最大权重的二分图匹配问题**

![image-20220405154032059](D:\HumanPose\image-20220405154032059.png)

见$Fig:b$，图中的点是身体部分检测的候选。边是所有可能连接的边。并且边被式子$(12)$计算衡量。二分图匹配是从边中选一个子集，并且其中每条边并不公用一个节点（$d_j^m \ne d_j^n$）。求出一种选择边的规则使得其具有最大权重
$$
\max_{Z_c} E_c = \max_{Z_c} \sum_{m \in D_{j_1}}\sum_{n \in D_{j_2}} E_{mn} \cdot z_{j_1,j_2}^{mn}
$$
$E_c$是第$c$种肢体的总权重。$Z_c$是$Z$关于第$c$种肢体的子集。解法：使用**匈牙利算法**

#### 匹配问题的优化

![image-20220411110008846](D:\HumanPose\image-20220411110008846.png)

1. 使用最少数量的边来构成身体骨架，而不是使用全图
2. 将问题分解成多个二部匹配子问题

$$
\max_Z E = \sum_{c=1}^C \max_{Z_c} E_c
$$

上诉三种方法的效果比较：数据集MPII（343张图片）

![image-20220411112147670](D:\HumanPose\image-20220411112147670.png)



## Dataset



1. MPII
2. COCO
3. COCO KeyPoint Dataset 子集

如果足部关键点不足会导致穿模，溜冰等问题，所以对COCO的一部分脚部实例进行了标注

![image-20220411111225770](D:\HumanPose\image-20220411111225770.png)实验结果表明：足部关键点检测隐含地帮助网络更准确地预测一些身体关键点，尤其是腿部关键点，如脚踝位置

![image-20220411111540470](D:\HumanPose\image-20220411111540470.png)

只有身体的数据集，网络并不能很好的预测脚踝。而包含脚踝的数据集可以。

### Experiment

![image-20220411115202787](D:\HumanPose\image-20220411115202787.png)

CM：置信图阶段

PAF：亲和场阶段

1. PAF需要更多的阶段收敛
2. 增加PAF通道数能增加TP的数量。CM的通道数量的增加提高了定位精度
3. 先验为PAF时，精度大幅提高

脚部标注对结果的影响：

![image-20220411115638165](D:\HumanPose\image-20220411115638165.png)

### 其他任务

车辆姿态估计
